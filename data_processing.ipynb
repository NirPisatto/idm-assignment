{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_file = 'all.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              CATEGORY  COUNT\n",
      "0     #METOO RECKONING     12\n",
      "1        2022 ELECTION     81\n",
      "2        2024 ELECTION    165\n",
      "3      ABORTION RIGHTS    123\n",
      "4   AFTER GEORGE FLOYD     16\n",
      "..                 ...    ...\n",
      "90      WAR IN UKRAINE    509\n",
      "91             WEATHER     55\n",
      "92   WESTERN WILDFIRES     19\n",
      "93         WHITE HOUSE    202\n",
      "94               WORLD    813\n",
      "\n",
      "[95 rows x 2 columns]\n",
      "                                               TITLE         CATEGORY\n",
      "0  A college professor called the police on two s...  CULTURE MATTERS\n",
      "1  Oscars producer says police were prepared to a...        CELEBRITY\n",
      "2  Jared Kushner interviewed by Jan. 6 committee ...     DONALD TRUMP\n",
      "3  House passes bill to cap out-of-pocket insulin...         CONGRESS\n",
      "4  Police shoot 'hero' after he disarms gunman, i...        U.S. NEWS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11334, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(src_file, quotechar=\"\\\"\", engine='python', usecols=[\"TITLE\", \"CATEGORY\"])\n",
    "# dataframe = pd.read_csv(src_file, sep='\\t', header=None, names=['ID', 'TITLE', 'URL', 'Source', 'CATEGORY', 'Key', 'Website', 'Timestamp'])\n",
    "\n",
    "# all_categories = [\"WORLD\", WHITE HOUSE]\n",
    "# print(dataframe.groupby(\"CATEGORY\").size().reset_index(name='COUNT'))\n",
    "category_count = dataframe.groupby(\"CATEGORY\").size().reset_index(name='COUNT')\n",
    "category_count = category_count[category_count[\"COUNT\"] > 10]\n",
    "\n",
    "dataframe = dataframe[dataframe[\"CATEGORY\"].isin(category_count[\"CATEGORY\"])]\n",
    "\n",
    "\n",
    "# dataframe = dataframe[dataframe[\"CATEGORY\"].isin([\"U.S. NEWS\", \"NEWS\", \"WORLD\"])]\n",
    "\n",
    "\n",
    "print(dataframe.groupby(\"CATEGORY\").size().reset_index(name='COUNT'))\n",
    "print(dataframe.head())\n",
    "dataframe.shape\n",
    "\n",
    "# print(category_count = category_count[category_count[\"COUNT\"] > 100])\n",
    "# print(dataframe[\"CATEGORY\"].unique())\n",
    "# print(dataframe)\n",
    "# print(dataframe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO missing data\n"
     ]
    }
   ],
   "source": [
    "#check for missing data\n",
    "if(any(dataframe.isnull().any())):\n",
    "    print('Missing Data\\n')\n",
    "    print(dataframe.isnull().sum())\n",
    "else:\n",
    "    print('NO missing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found\n",
      "Number of duplicate rows=  44\n",
      "Dropping duplicates\n",
      "\n",
      "(11290, 2)\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate\n",
    "if(any(dataframe.duplicated())==True):\n",
    "    print('Duplicate rows found')\n",
    "    print('Number of duplicate rows= ', dataframe[dataframe.duplicated()].shape[0])\n",
    "    dataframe.drop_duplicates(inplace=True,keep='first')\n",
    "    dataframe.reset_index(inplace=True,drop=True)\n",
    "    print('Dropping duplicates\\n')\n",
    "    print(dataframe.shape)\n",
    "else:\n",
    "    print('NO duplicate data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/misapisatto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/misapisatto/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/misapisatto/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# Function for cleaning and tokenize the headline\n",
    "def tokenize(doc):\n",
    "  document = doc.lower() # convert the content of the headline to lowercase\n",
    "  document = re.sub(r'\\d+', '', document) # remove all of the digits inside of the content (using regular expressions)\n",
    "  document = document.translate(str.maketrans('', '', string.punctuation)) # remove the puntuations (, . ! # ...)\n",
    "  document = document.strip() # remove the spaces at the start and end of the headline\n",
    "  return [wnl.lemmatize(token) for token in word_tokenize(document) if token not in stopwords.words('english')]\n",
    "  # tokenize the headlines\n",
    "  # and then filter only the words that are not in the english stopwords (words that are commonly used and give no benifits to the classifier)\n",
    "  # and finally lemmatize all of the tokens\n",
    "\n",
    "# The preprocess pipeline\n",
    "preprocessor = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)), # passing custom tokenizer method for the CountVectorizer to use\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "])\n",
    "\n",
    "tfidf_dataset = preprocessor.fit_transform(dataframe[\"TITLE\"].values) # process the training dataset\n",
    "# tfidf_test = preprocessor.transform(X_test.values) # process the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         CULTURE MATTERS\n",
      "1               CELEBRITY\n",
      "2            DONALD TRUMP\n",
      "3                CONGRESS\n",
      "4               U.S. NEWS\n",
      "               ...       \n",
      "11285          FIRST READ\n",
      "11286     MORNING RUNDOWN\n",
      "11287    ISRAEL-HAMAS WAR\n",
      "11288           U.S. NEWS\n",
      "11289      WAR IN UKRAINE\n",
      "Name: CATEGORY, Length: 11290, dtype: object\n",
      "[21 11 24 ... 45 89 90]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "class_label = le.fit_transform(dataframe[\"CATEGORY\"])\n",
    "\n",
    "print(dataframe[\"CATEGORY\"])\n",
    "print(class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tfidf_dataset.toarray(),\n",
    "    class_label,\n",
    "    test_size = 0.3 # the size of the testing dataset (in percentage between 0 and 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41]\n",
      "IMMIGRATION\n",
      "0.43844109831709477\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Decision Tree\n",
    "DTClass = DecisionTreeClassifier(criterion=\"gini\", splitter=\"best\", random_state=40)\n",
    "DTClass.fit(X_train, y_train)\n",
    "y_pred = DTClass.predict(X_test)\n",
    "\n",
    "o = DTClass.predict(preprocessor.transform([\"Slashing Central American aid could drive more migrants to the U.S.\"]).toarray())\n",
    "print(o)\n",
    "print(dataframe[\"CATEGORY\"].values[np.where(class_label == o)[0]][0])\n",
    "\n",
    "# print(\"accuracy score of Decision Tree:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45]\n",
      "ISRAEL-HAMAS WAR\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "o = DTClass.predict(preprocessor.transform([\"Slashing Central American aid could drive more migrants to the U.S.\"]).toarray())\n",
    "print(o)\n",
    "print(dataframe[\"CATEGORY\"].values[np.where(class_label == o)[0]][0])\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34513274336283184\n",
      "accuracy score of Naive Bayes:\n",
      "Predicted Category: U.S. NEWS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "naive_bayes_model = MultinomialNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe['TITLE'], dataframe['CATEGORY'], test_size=0.1, random_state=42)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "naive_bayes_model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "y_pred = naive_bayes_model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(accuracy)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"accuracy score of Naive Bayes:\")\n",
    "\n",
    "new_title_vectorized = vectorizer.transform([\"At least five states are considering requiring full minimum wages for tip earners this year\"])\n",
    "\n",
    "predicted_category = naive_bayes_model.predict(new_title_vectorized)\n",
    "\n",
    "print(f'Predicted Category: {predicted_category[0]}')\n",
    "# print(accuracy)\n",
    "# print(conf_matrix)\n",
    "# print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    CONSUMER       0.00      0.00      0.00       1.0\n",
      "   U.S. NEWS       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       1.0\n",
      "   macro avg       0.00      0.00      0.00       1.0\n",
      "weighted avg       0.00      0.00      0.00       1.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/misapisatto/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
